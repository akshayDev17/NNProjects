{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- generative adversarial network\n",
    "\n",
    "    - generative: generate a new probability distribution function that *in-th-end* mimics the original probability distribution of a dataset\n",
    "    \n",
    "    - adversarial: some conflict or opposition, as exists between the 2 NNs, generator and discriminator, which compete against each other\n",
    "\n",
    "- 2 main neural-net models:\n",
    "\n",
    "    - **discriminator**:\n",
    "    \n",
    "        - discriminates between 2 different classes of data\n",
    "        \n",
    "        - for instance, a model built to detect *fake vs real* usually uses this. in such case the model outputs 1 ==> real, 0 ===> fake\n",
    "        \n",
    "    - **generator**:\n",
    "    \n",
    "        - trained on training data, sampled from some true distribution D, and when given some standard random distribution Z(of some other parameters), produces a distribution $\\hat{\\textrm{D}}$ which is as close to D according to some closeness metric.\n",
    "        \n",
    "        - symbolically represented as G.\n",
    "        \n",
    "        - G(Z) = $\\hat{\\textrm{D}}$, such that $\\hat{\\textrm{D}}$ $\\approx$ D\n",
    "        \n",
    "- hence, G learns to generate a sample, and then discriminator is the one that checks whether this sample is a fake or not, and if discriminator says that its a fake, G has to learn something more(i.e. optimise some objective function), so as to generate a sample which the discriminator actually classifies as a real sample, and in this way $\\hat{\\textrm{D}}$ $\\approx$ D\n",
    "\n",
    "- if decision made by the discriminator is wrong, feedback to fine-tune it, and fine-tuning of the generator, as part of backprop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Mechanism\n",
    "\n",
    "- weights and biases for each of the generator and discriminator\n",
    "- while training one the other is held constant, i.e. not trained\n",
    "- <font size=\"4\">training the discriminator</font> is much easier\n",
    "    - label the artificial instances(samples generated by the generator) as y = 0, real instances(from true dataset) as y=1\n",
    "    - these 2 collection of samples are then combined into 1 large set, and the discriminator learns to output y = 0 or y=1, thus the discriminator is involved with a binary classification task\n",
    "- <font size=\"4\">training the generator</font>\n",
    "    - the discriminator weights and biases are kept fixed, so that it doesn't become so strong such that the generator is never able to beat it\n",
    "    - while training the generator, its outputs, i.e. the artificial instances are labelled 1, so as to fool the discriminator into believing that its been provided with real samples\n",
    "    - if the discriminator is rather strong enough to classify this artificial instance as y=0, we backprop this information to, the weights and biases for the generator are adjusted, upto an extent where the discriminator outputs the label as 0.5, meaning that it has become confused, or in other words, *generator has become smart enough* to fool the discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function of GAN\n",
    "\n",
    "\n",
    "## Notations\n",
    "- p.d.f. of true dataset d$_{\\textrm{true}}$: p$_{\\textrm{data}}$(x), where x = true sample belonging to d$_{\\textrm{true}}$, and X = random variable that denotes the sample belonging to d$_{\\textrm{true}}$\n",
    "\n",
    "- discriminator D(x; $\\theta$) ==> variables before \";\" are input parameters, after \";\" are parameters that we need to optimize\n",
    "    - x is passed into D(x; $\\theta_2$), which gives us D(x), a p.d.f. that denotes probability of x belonging in D, i.e. being a true/real sample\n",
    "    \n",
    "    - since its a p.d.f., D(x) $\\epsilon$\\[0, 1\\]\n",
    "\n",
    "- a priori probability distribution on the input noise variable p$_{\\textrm{Z}}$(z) is defined, which will be fed into the generator G(z; $\\theta_1$)\n",
    "\n",
    "    - the generator outputs a sample, x$_{\\textrm{G}}$\n",
    "    \n",
    "    - goal: p$_{\\textrm{G}}$(x$_{\\textrm{G}}$) = p$_{\\textrm{data}}$(x)\n",
    "    \n",
    "    - this sample is also fed to the D(x; $\\theta_2$), with a label = 0\n",
    "    \n",
    "    - the output, when an artificial sample is given to the discriminator, which is a p.d.f., just like D(x), is D(G(z))\n",
    "\n",
    "- <font color=\"red\">Note</font>: G() and D() are differentiable functions, or else updation will not be possible\n",
    "\n",
    "## Binary crossentropy loss\n",
    "\n",
    "- L(y, $\\hat{\\textrm{y}}$) = ylog($\\hat{\\textrm{y}}$) + (1-y)log(1-$\\hat{\\textrm{y}}$)\n",
    "\n",
    "- for samples coming from d$_{\\textrm{true}}$, y = 1, $\\hat{\\textrm{y}}$ = D(x) \n",
    "    \n",
    "    - hence, L(1, D(x)) = log(D(x))\n",
    "    \n",
    "- for samples coming from generator, y = 0, $\\hat{\\textrm{y}}$ = D(G(z))\n",
    "    \n",
    "    - hence, L(0, D(G(z) ) = log( 1 - D(G(z)) )\n",
    "\n",
    "## Discriminator\n",
    "\n",
    "- objective: correctly classifiy fake from real\n",
    "\n",
    "- maximise L(1, D(x) ) and L(0, D(G(x) ), since these are the loss functions for the discriminator\n",
    "\n",
    "- we already know that D(x) and D(G(z)) are p.d.f.'s, \n",
    "    \n",
    "    - hence log(D(x)) $\\epsilon (-\\infty$, 0], so the max value for this function is 0, which means that D(x) = 1.\n",
    "    \n",
    "    - hence 1-D(G(z)) $\\epsilon [0, 1]$, which means that log( 1 - D(G(z)) ) $\\epsilon \\, (-\\infty$, 0], so the max value for this function is 0, which means that D(G(z)) = 0\n",
    "    \n",
    "- these results are anyways expected, i.e. sample from the generator should be classified as to having 0 probability of belonging in d$_{\\textrm{true}}$, and samples from d$_{\\textrm{true}}$ should be classified as to having full probability of belonging in d$_{\\textrm{true}}$\n",
    "\n",
    "- hence, the net loss function becomes L = max.( log(D(x)) + log( 1 - D( G(z) ) ) )\n",
    "\n",
    "## Generator\n",
    "\n",
    "- so as to fool the discriminator, all the generator has to do is D(G(z)) = 1, since this corresponds to being classified as a true sample\n",
    "\n",
    "- this basically means that log(1 - D(G(z)) ) $\\rightarrow -\\infty$ \n",
    "<img src=\"generator.png\"/>\n",
    "    \n",
    "- hence the goal is to min. ( log(1 - D(G(z)) ) )\n",
    "    \n",
    "    - its actually generally represented as min.( log(D(x)) + log(1 - D(G(z)) ) ), although D(x) has nothing to do with generator G.\n",
    "    \n",
    "\n",
    "Hence its very obvious that the generator and discriminator have the exact **<font color=\"red\">opposite</font>** objective functions, and that's why the term **adversarial** is used\n",
    "\n",
    "min.$_{\\textrm{G}}$ max.$_{\\textrm{D}}$ (log(D(x)) + log(1 - D(G(z)) ))\n",
    "\n",
    "<font size=\"4\">On including all training samples, we get</font>:\\\n",
    "V(G, D) = min.$_{\\textrm{G}}$ max.$_{\\textrm{D}}$ ( <font size=\"4\">E$_{x \\epsilon p_{\\textrm{data}}(x)}$</font>$\\left[\\textrm{log}\\left(D(x)\\right)\\right]$ +  <font size=\"4\">E$_{z \\epsilon p_{\\textrm{z}}(Z)}$</font>$\\left[\\textrm{log}\\left(1-D(G(z))\\right)\\right]$), where E: expectation value over the respective p.d.f. of p$_{\\textrm{data}}$(x) and p$_{\\textrm{z}}$(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best discriminator\n",
    "\n",
    "- fix G, optimal discriminator D is given by:\n",
    "    - D$_{\\textrm{G}}^{*}$(x) =  $\\frac{\\textrm{p}_{\\textrm{data}}(x)}{\\textrm{p}_{\\textrm{data}}(x)+\\textrm{p}_{\\textrm{G}}(x)}$\n",
    "\n",
    "- since G is fixed, the loss function becomes max.(sum-of-expected-values)\n",
    "\n",
    "- E$_{\\textrm{p(x)}}$\\[x\\] = $\\int_{\\textrm{x}}xp(x)dx$\n",
    "    \n",
    "- hence V(G, D) = max.$_{\\textrm{D}}$(<font size=\"4\">E$_{x \\epsilon p_{\\textrm{data}}(x)}$</font>$\\left[\\textrm{log}\\left(D(x)\\right)\\right]$ +  <font size=\"4\">E$_{z \\epsilon p_{\\textrm{z}}(Z)}$</font>$\\left[\\textrm{log}\\left(1-D(G(z))\\right)\\right]$)\n",
    "    \n",
    "    - \\begin{equation}\n",
    "        V(G, D) = \\int_x p_{\\textrm{data}}(x)\\textrm{log(D(x))dx} + \\int_z p_{\\textrm{z}}(z)\\textrm{log(1-D(G(z)))dz} \\end{equation}\n",
    "        \n",
    "- for a given p.d.f. p$_x$(x), the p.d.f. of a function f(x) can also be calculated\n",
    "    \n",
    "    - this is called change of variable\n",
    "    \n",
    "    - P$_y$(y) = p$_x(f^{-1}(y)) \\frac{d(f^{-1}(y)}{dy} $, where y = f(x)\n",
    "    \n",
    "- we know that our generator produces x' = G(z), such that we want the distribution of this x' to mimic that of x\n",
    "    \n",
    "    - thus, we get p$_{\\textrm{G}}$(x') = p$_{\\textrm{z}}(G^{-1}) \\frac{d(G^{-1}(x')}{dx'}$\n",
    "    \n",
    "    - **strong assumption: G is invertible**\n",
    "    \n",
    "    - performing *change of variable* for the expression $\\int_z p_{\\textrm{z}}(z)\\textrm{log(1-D(G(z)))dz}$, we get $\\int_{x'} p_{\\textrm{z}}(G^{-1}(x'))\\textrm{log(1-D(x'))}dG^{-1}(x')$\n",
    "    \n",
    "    - multiplying and dividing the above expression by dx', inside the integral, we obtain $\\int_{x'} p_{\\textrm{z}}(G^{-1}(x'))\\frac{dG^{-1}(x')}{dx'} $ . log(1-D(x'))dx'\n",
    "    \n",
    "    - this becomes $\\int_{x'} \\textrm{p}_{\\textrm{G}}(x') $ . log(1-D(x'))dx' \n",
    "    \n",
    "\n",
    "- hence V(G, D) = $\\int_x p_{\\textrm{data}}(x)\\textrm{log(D(x))dx}$  + $\\int_{x'} \\textrm{p}_{\\textrm{G}}(x')$. log(1-D(x'))dx'\n",
    "\n",
    "    - we assume that our generator is currently doing its best, i.e. its generating x' with the same distribution as x, thus making x' = x\n",
    "    \n",
    "    - hence V(G, D) = $\\int_x \\left(p_{\\textrm{data}}(x)\\textrm{log(D(x))} \\, + \\, \\textrm{p}_{\\textrm{G}}(x).log(1-D(x))\\right)dx$\n",
    "    \n",
    "- this above V(G, D) needs to be maximised, which means that the first derivative w.r.t. D(x) should be 0, since the **argument here is D(x)**, i.e. the discriminator, and not the random variable x.\n",
    "    \n",
    "    - $\\frac{d(V(G, D))}{dD(x)}_{D = D^{*}} = 0$\n",
    "    \n",
    "    - $\\frac{d(V(G, D))}{dD(x)}$ = $\\frac{p_{\\textrm{data}}(x)}{\\textrm{D(x)}} \\, - \\, \\frac{\\textrm{p}_{\\textrm{G}}(x)}{1-D(x)}$ = 0 \n",
    "    \n",
    "    - on rearranging the terms, we finally obtain: <font size=\"4\"> D$_{\\textrm{G}}^{*}$(x) =  $\\frac{\\textrm{p}_{\\textrm{data}}(x)}{\\textrm{p}_{\\textrm{data}}(x)+\\textrm{p}_{\\textrm{G}}(x)}$</font>\n",
    "    \n",
    "    - just to prove that D is maximum at this value, lets evaluate $\\frac{d^2(V(G, D))}{dD(x)^2}$:\n",
    "    \\begin{equation}\n",
    "    \\frac{d^2(V(G, D))}{dD(x)^2} = -\\frac{p_{\\textrm{data}}(x)}{\\textrm{D(x)}^{2}} - \\frac{\\textrm{p}_{\\textrm{G}}(x)}{\\left(1-D(x)\\right)^{2}} \\\\\n",
    "    \\textrm{since   } p_{\\textrm{data}}(x) \\, \\epsilon \\, [0, 1] \\textrm{ and } p_{\\textrm{G}}(x) \\, \\epsilon \\, [0, 1] \\, \\, \\Rightarrow \\, \\, D_{\\textrm{G}}^{*}\\textrm{(x)} \\ge 0\n",
    "    \\end{equation}\n",
    "    \n",
    "    - hence the second derivative is negative, thus proving that this is in fact the value at which the objective is maximized.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the best generator\n",
    "\n",
    "- now that the best discriminator is known, lets keep it fixed and try to optimise for the generator, i.e. min.$_{\\textrm{G}}$(V(G, D$_{\\textrm{G}}^{*}$(x)))\n",
    "\n",
    "- optimal generator should have the condition that p$_{\\textrm{G}}$(x) = p$_{\\textrm{data}}$(x)\n",
    "\n",
    "- using D$_{\\textrm{G}}^{*}$(x) =  $\\frac{\\textrm{p}_{\\textrm{data}}(x)}{\\textrm{p}_{\\textrm{data}}(x)+\\textrm{p}_{\\textrm{G}}(x)}$, we get: V(G, D$_{\\textrm{G}}^{*}$(x)) = $\\int_x \\left(p_{\\textrm{data}}(x)\\textrm{log}\\left(\\frac{\\textrm{p}_{\\textrm{data}}(x)}{\\textrm{p}_{\\textrm{data}}(x)+\\textrm{p}_{\\textrm{G}}(x)}\\right) \\, + \\, \\textrm{p}_{\\textrm{G}}(x).log\\left(\\frac{\\textrm{p}_{\\textrm{G}}(x)}{\\textrm{p}_{\\textrm{data}}(x)+\\textrm{p}_{\\textrm{G}}(x)}\\right)\\right)dx$\n",
    "\n",
    "- now add and subtract these 2 terms : log(2).p$_{\\textrm{data}}$(x) , log(2).p$_{\\textrm{G}}$(x)\\\n",
    "we thus have $\\int_x \\left(-\\log2.\\left(p_{\\textrm{data}}(x)+ p_{\\textrm{G}}(x)\\right)\\, + \\, p_{\\textrm{data}}(x)\\textrm{log}\\left(\\frac{2.\\textrm{p}_{\\textrm{data}}(x)}{\\textrm{p}_{\\textrm{data}}(x)+\\textrm{p}_{\\textrm{G}}(x)}\\right) \\, + \\, \\textrm{p}_{\\textrm{G}}(x).log\\left(\\frac{2.\\textrm{p}_{\\textrm{G}}(x)}{\\textrm{p}_{\\textrm{data}}(x)+\\textrm{p}_{\\textrm{G}}(x)}\\right)\\right)dx$\n",
    "\n",
    "    - this simplifies to <font size=\"4\" color=\"red\">-log4 + KL$\\left[p_{\\textrm{data}}(x) || \\frac{\\textrm{p}_{\\textrm{data}}(x) + \\textrm{p}_{\\textrm{G}}(x)}{2}\\right]$ + KL$\\left[p_{\\textrm{G}}(x) || \\frac{\\textrm{p}_{\\textrm{data}}(x) + \\textrm{p}_{\\textrm{G}}(x)}{2}\\right]$ </font>\n",
    "\n",
    "- remember that x' = G(z), z = random noise, x' = sample generated by the generator\n",
    "    \n",
    "    - also <font color=\"red\" size=\"4\">p$_{\\textrm{G}}$(x') = p$_{\\textrm{z}}(G^{-1}) \\frac{d(G^{-1}(x')}{dx'}$</font>\n",
    "    \n",
    "- the summation of KL-divergence above is represented by a new divergence function, called the **Jensen-Shanon Divergence** \n",
    "    \n",
    "    - JSD(a || b) = $\\frac{1}{2}\\left[ \\textrm{KL(a||c)} +  \\textrm{KL(b||c)} \\right]$, where c = $\\frac{\\textrm{a+b}}{2}$\n",
    "    \n",
    "- KL divergence becomes 0 at p$_{\\textrm{G}}$(x) = p$_{\\textrm{data}}$(x) (2 same quantities)\n",
    "\n",
    "- **hence, tuning the JSD to 0 is the main objective**\n",
    "\n",
    "- observe that when G = G*, p$_{\\textrm{G}}$(x) = p$_{\\textrm{data}}$(x), even if D = D$_{\\textrm{G}}^{*}$,<font size=\"4\" color=\"red\">D = 1/2</font>, hence our generator has confused even the best discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the loss function\n",
    "\n",
    "- <font size=\"5\" color=\"blue\">for the j$^{\\textrm{th}}$ iteration</font>:\n",
    "    - <font size=\"4\" color=\"purple\">for k steps do</font>:\n",
    "        * Sample mini-batch of **m noise samples** {z$^{(1)}$, z$^{(2)}$, .... z$^{(\\textrm{m})}$ } from noise prior p$_{\\textrm{G}}$(z)\n",
    "        * Sample mini-batch of **m data samples** {x$^{(1)}$, x$^{(2)}$, .... x$^{(\\textrm{m})}$ } from dataset-distribution, p$_{\\textrm{data}}$(x)\n",
    "        * Update the discriminator by **ascending**(<font color=\"green\">since we want to maximise the cost w.r.t. discriminator</font>) its *stochastic*(basically for the current mini-batch) gradient)\\\n",
    "            $\\nabla$<font size=\"4\">$_{\\theta_{\\textrm{d}}}$</font> $\\frac{1}{\\textrm{m}} \\sum \\limits_{\\textrm{i=1}}^{\\textrm{m}} $log(D(x$^{(\\textrm{i})}$)) + log( 1 - D( G(z$^{(\\textrm{i})}$) ) ), where $\\theta_{\\textrm{d}}$ denoted parameters of the discriminator network\n",
    "    * <font size=\"4\" color=\"purple\">endfor</font>\n",
    "    * Sample mini-batch of **m noise samples** {z$^{(1)}$, z$^{(2)}$, .... z$^{(\\textrm{m})}$ } from noise prior p$_{\\textrm{G}}$(z)\n",
    "    * Update the generator by **descending**(<font color=\"red\">since we want to minimise the cost w.r.t. generator</font>) its *stochastic*(basically for the current mini-batch) gradient)\n",
    "        * $\\nabla$<font size=\"4\">$_{\\theta_{\\textrm{g}}}$</font> $\\frac{1}{\\textrm{m}} \\sum \\limits_{\\textrm{i=1}}^{\\textrm{m}}$ log( 1 - D( G(z$^{(\\textrm{i})}$) ) ), where $\\theta_{\\textrm{g}}$ denoted parameters of the generator network\n",
    "* <font size=\"5\" color=\"blue\">endfor</font>\n",
    "* practically speaking, at the starting iterations of this loss function, when the generator isn't itself *smart enough* to fool the discriminator, i.e. discriminator can easily identify the sample produced by the generator, D(G(z)) = 0\n",
    "    \n",
    "    * hence the gradient for the loss function log(1 - D(G(z)) is almost 0, since tangent drawn to y = log(1-D(G(z))) at D(G(z)) = 0  is almost a flat one, it would seem as if convergence criterion has reached, but its not so\n",
    "    * to overcome this, in practical scenarios, the function <font size=\"4\">argmax$_{\\textrm{G}}$(E$_{p_{z}(z)}$[log(D(G(z))])</font> is used instead\n",
    "    \n",
    "    * even for the initial iterations where D(G(z)) = 0, the slope would be very large, thus informing the model that we have a lot to go before concluding that convergence is achieved. Also, since the gradient is high, it usually corresponds to a jump in the steepest descent algorithm for optimisation.\n",
    "    \n",
    "    * don't worry, <font size=\"4\" color=\"blue\">the objective for the discriminator remains the same</font>, since it doesn't suffer from this gradient-problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawbacks of GAN\n",
    "\n",
    "1. Vanishing Gradients\n",
    "    \n",
    "    1. this is observed for the generator, and that's why the objective was changed, as mentioned in the previous section.\n",
    "    \n",
    "    2. let $\\theta_{\\textrm{g}} = \\theta,\\,\\, \\theta_{\\textrm{d}} = \\phi$, $\\frac{\\partial \\textrm{V(G, D)}}{\\partial \\theta} = \\nabla_{\\theta}$[E$_{p_{z}(z)}$[log(1-D$_{\\phi}$(G$_{\\theta}$(z)))]] = E<font size=\"4\">$_{\\textrm{p}_{\\textrm{z}}(z)}\\left[ \\frac{\\partial \\textrm{G}_{\\theta}(z)}{\\partial \\theta} \\frac{1}{\\textrm{D}_{\\phi}(\\textrm{G}_{\\theta}(z))-1} \\frac{\\partial \\textrm{D}_{\\phi}(\\textrm{G}_{\\theta}(z))}{\\partial \\textrm{G}_{\\theta}(z)} \\right]$</font>\n",
    "    \n",
    "    3. we already know that for perfect generator, x' = x, i.e. x = G(z), E<font size=\"4\">$_{\\textrm{p}_{\\textrm{G}}(x)}$ = $ \\frac{\\partial x}{\\partial \\theta} \\frac{1}{\\textrm{D(x)-1}} \\frac{\\partial D(x)}{\\partial x}$</font>\n",
    "    \n",
    "    4. with our basic assumption that after **k steps, a perfect discriminator is obtained**, which will be able to perfectly classify D(G(x)), or rather samples generated from generator, as always being D(X) = 0. Hence all samples drawn from the generator will have D(x) = 0, hence the derivative of D(x) w.r.t. $\\theta$ turns to 0.\n",
    "    \n",
    "    5. this is the mathematical display of vanishing gradients for the generator\n",
    "    \n",
    "    6. changing the loss function to max.(log(D$_{\\phi}$(G$_{\\theta}$(x)))) or to put it more precisely, max.(E$_{\\textrm{p}_{\\textrm{z}}(z)}$\\[log(D$_{\\phi}$(G$_{\\theta}$(x)))\\])\n",
    "    \n",
    "2. Mode Collapse\n",
    "    \n",
    "    1. generator collapses to a setting where it ends up **always producing the same outputs**\n",
    "    \n",
    "    2. the p.d.f. function of the true dataset is a complex, multi-modal function, having different peaks such that there can be a subset of all classes concentrated in these peaks\n",
    "    \n",
    "    3. lets consider MNIST hadnwritten-digit dataset\n",
    "    \n",
    "    4. it may so happen that we have different curves for p.d.f. for each class(not talking about the p.d.f. of the true entire data here). \\\n",
    "    We can see below that 0 can be represented in first gaussian, and 9 can be represented in the last one \n",
    "    \n",
    "    5. hence the generator might find it hard to learn this multi-modal distribution(here modes means total number of classes) and since its main objective is to fool the discriminator, <font color=\"green\">instead of learning from all modes</font>, <font color=\"red\">it may just end up learning from 1 of these modes in a near-perfect manner</font>(this is an easier task), such that its easily able to replicate the samples that constitute that particular mode.\n",
    "    \n",
    "    6. as the discriminator gets better w.r.t. telling apart the artificial and real samples belonging to 1 mode, the generator has to either produce better samples for that mode or it can simply learn to produce better samples from some other mode for which the discriminator has not yet learnt to tell the real-n-fake apart.\n",
    "    \n",
    "    7. hence, in the above point, if the generator ends up picking the former option many number of times, mode collapse will occur, or at-the-very-least has high chances of occurring.\n",
    "    \n",
    "    8. an analogy to understand this is that *instead of becoming a jack of all trades*, <u>the generator decides to become the master of one</u>\n",
    "    \n",
    "3. hard to achieve Nash equilibrium\n",
    "\n",
    "    1. [Salimans 2016](https://arxiv.org/abs/1606.03498) discusses this problem in detail\n",
    "    \n",
    "    2. principally GANs should train in such a way that both the generator and dsicriminator find a nash equilibrium at the end of this *2 player, non-cooperative game.*\n",
    "    \n",
    "    3. however, each model updates its cost with no regards of how the other is updating itself.\n",
    "    \n",
    "    4. hence the gradients of both models, **<font color=\"red\">concurrently cannot guarantee convergence</font>**\n",
    "    \n",
    "    5. lets assume f$_1$(x) = xy, f$_2$(y) = -xy, such that their respective objectives are to maximize and minimize x.y\n",
    "    \n",
    "    6. with each update of these functions, huge oscillations in these functions, instability becomes worse with time\n",
    "    \n",
    "4. Problem with counting\n",
    "    \n",
    "    1. fail to differentiate between number of objects that should occur in a generated image\n",
    "    \n",
    "5. Problem with perspective\n",
    "    \n",
    "    1. unable to differentiate between the front view and rear view\n",
    "    \n",
    "    2. this is seen when GANs are learning from 3D-objects(images are 3D in a sense that some perspective is involved in that image) to generate their 2D images.\n",
    "    \n",
    "6. problem with gloabl structure\n",
    "\n",
    "    1. problems in understanding holistic structure similar to the above perspective problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "(train_images, train_labels), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "train_images = train_images/255. \n",
    "print(train_images.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since tensorflow v2 has removed `placeholder`, we have to force tensorflow to use the v1 components, and rather shut down the v2 behavior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(train_images[0]))\n",
    "plt.imshow(train_images[0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# trying to change the visualisation for better resolution\n",
    "from skimage.transform import resize\n",
    "img_down = resize(train_images[0], (14, 14))\n",
    "img_up = resize(train_images[0], (56, 56))\n",
    "img_2 = resize(train_images[0], (448, 448))\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 5))\n",
    "\n",
    "ax[0].imshow(img_down, cmap='gray')\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "ax[1].imshow(img_up, cmap='gray')\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "ax[2].imshow(img_2, cmap='gray')\n",
    "ax[2].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets set the training parameters:\n",
    "* learning rate\n",
    "* batch size\n",
    "* number of epochs\n",
    "\n",
    "and the neural net params:\n",
    "* image dimensions(flattened)\n",
    "* hidden dimensions of the generated image(flattened, number of neurons in this layer)\n",
    "* hidden dimensions of the discriminator NN(flattened, number of neurons in this layer)\n",
    "* dimensions of the random noise, z(flattened out value, $100\\times1$ vector produced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate, batch_size, epochs = 0.0002, 128, 100000\n",
    "\n",
    "image_dim, gen_hidden_dim, disc_hidden_dim, z_noise_dim = 784, 256, 256, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicesList = [i for i in range(train_images.shape[0])]\n",
    "from random import choices\n",
    "def fetchBatch():\n",
    "    choiceOptions = choices(indicesList, k=batch_size)\n",
    "    x_train_arr = np.array([train_images[i] for i in choiceOptions])\n",
    "#     x_train_arr = x_train_arr/255.\n",
    "    return x_train_arr.reshape(batch_size, image_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fetchBatch()[0].reshape([28, 28]))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image dimensions is 784, since it has to generate an image of dimensions $28\\times28$\n",
    "\n",
    "the function below, called <u>xavier initialization</u>, helps in achieving the convergence criterion faster.\n",
    "\n",
    "* its an initialization method after all, used for initializing weights and biases\n",
    "\n",
    "* With each passing layer, we want the variance to remain the same. \n",
    "    * This helps us keep the signal from exploding to a high value or vanishing to zero. \n",
    "    \n",
    "    * In other words, we need to initialize the weights in such a way that the variance remains the same for x and y.(x = input to current layer, y = output of the current layer) \n",
    "\n",
    "* we ignore the updation of biases for this proof:\n",
    "    \n",
    "    * <img src=\"linearNeuron.png\" />\n",
    "    * consider a linear neuron: y = $\\sum\\limits_i w^ix^i$ (weights is a vector, rather than a matrix, x is the feature vector for a sample)\n",
    "    \n",
    "    * var(ab) = E(a)$^2$var(b) + E(b)$^2$var(a) + var(a).var(b)\n",
    "    \n",
    "    * **assumption : weights and samples are drawn from a standard distribution, hence their respective mean values = 0**\n",
    "    \n",
    "    * hence var(w$^i$x$^i$) = var(w$^i$).var(x$^i$), var(y) = $\\sum\\limits_i$ var(w$^i$).var(x$^i$)\n",
    "    \n",
    "    * since the samples and weights are identically distributed(no overall trends–the distribution doesn’t fluctuate and all items in the sample are taken from the same probability distribution), var(w$^i$) = var(w$^j$), var(x$^i$) = var(x$^j$).\n",
    "    \n",
    "    * thus var(y) = N.var(w).var(x), we wanted **var(y) = var(x)**, hence **var(w) = $\\frac{1}{N}$**, <font color=\"purple\">N: feature-dimensionality</font>\n",
    "    \n",
    "* We need to pick the weights from a Gaussian distribution with zero mean and a variance of 1/N, where N specifies the number of input neurons. \n",
    "    * This is how it’s implemented in the Caffe library. \n",
    "    \n",
    "* In the original paper, the authors take the average of the number input neurons and the output neurons. \n",
    "    \n",
    "    * <img src=\"normalNetwork.jpeg\" />\n",
    "     \n",
    "    * So the formula becomes:\n",
    "    var(w) = $\\frac{1}{N_{\\textrm{avg}}}$, where $N_{\\textrm{avg}}$ = <font size=\"4\">$\\frac{N_{\\textrm{in}}+N_{\\textrm{out}}}{2}$</font>\n",
    "    \n",
    "    * in the above image, N$_{\\textrm{in}}$ = 3, N$_{\\textrm{out}}$ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(shape):\n",
    "    return tf.random.normal(\n",
    "        shape=shape,\n",
    "        stddev=1./tf.sqrt(shape[0]/2.0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <font size=\"4\">Variables</font>:\n",
    "\n",
    "    1. Variable tensors are used when the values require updating within a session. \n",
    "    \n",
    "    2. It is the type of tensor that would be used for the weights matrix when creating neural networks, since these values will be updated as the model is being trained.\n",
    "    \n",
    "    3. Something to note is that declaring a variable tensor does not automatically initialize the values.\n",
    "    \n",
    "    4. The values need to be intialized explicitly when starting a session.\n",
    "    \n",
    "    5. Something to note is that declaring a variable tensor does not automatically initialize the values. \n",
    "        1. The values need to be intialized explicitly when starting a session using one of the following: \\\n",
    "        `tf.global_variables_initializer().run()`\\\n",
    "        `session.run(tf.global_variables_initializer())`\n",
    "        \n",
    "        2. we have chosen the latter.\n",
    "    \n",
    "    6. In Python-based TensorFlow, tf.Variable instance have the same lifecycle as other Python objects. \n",
    "    \n",
    "    7. When there are no references to a variable it is automatically deallocated.\n",
    "    \n",
    "    8. Variables can also be named(`a = tf.Variable(..., name=\"myNameIsJohnCena)`) which can help you track and debug them. \n",
    "    \n",
    "    9. You can give two variables the same name.\n",
    "    \n",
    "    10. Variable names are preserved when saving and loading models. \n",
    "    \n",
    "        1. By default, variables in models will acquire unique variable names automatically, so you don't need to assign them yourself unless you want to.\n",
    "        \n",
    "    11. You can turn off gradients for a variable by setting trainable to false at creation. \n",
    "         1. An example of a variable that would not need gradients is a training step counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    \"disc_H\": tf.Variable(xavier_init([image_dim, disc_hidden_dim])),\n",
    "    \"disc_final\": tf.Variable(xavier_init([disc_hidden_dim, 1])),\n",
    "    \"gen_H\": tf.Variable(xavier_init([z_noise_dim, gen_hidden_dim])),\n",
    "    \"gen_final\": tf.Variable(xavier_init([gen_hidden_dim, image_dim]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"disc_H\": tf.Variable(xavier_init([disc_hidden_dim])),\n",
    "    \"disc_final\": tf.Variable(xavier_init([1])),\n",
    "    \"gen_H\": tf.Variable(xavier_init([gen_hidden_dim])),\n",
    "    \"gen_final\": tf.Variable(xavier_init([image_dim]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\\_H** means that the parameter is defined for the hidden layer of that model(generator/discriminator)\\\n",
    "**\\_final** means that the parameter is defined for the final/output layer of that model(generator/discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights[\"disc_H\"], \"\\n\\n\\nshape of discriminator's hidden layer wiehgts are :\", weights[\"disc_H\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Placeholder</font>\n",
    "1. Variable that we can declare, but dont need to assign any value to immediately\n",
    "\n",
    "2. allows us to create our operations and build our computation graph, without needing the data\n",
    "\n",
    "3. we then feed data into the graph through these placeholders.\n",
    "\n",
    "4. it is *a place in memory where we will store value later on.*\n",
    "\n",
    "5. its value is defined in the `feed_dict` argument that is provided in the `session.run` function\n",
    "\n",
    "6. placeholder don't need to be statically-sized, but for the network to work for only a certain dimension-value, we provide the shape in such a way that the first element of the shape can be anything, but the last element has to be `z_noise_dim` and `image_dim` for `z_input` and `x_input` respectively.\n",
    "\n",
    "`tf.name_scope` \n",
    "1. So as the name suggests, the scope functions create a scope for the names of the ops you create inside. \n",
    "\n",
    "2. This has an effect on how you refer to tensors, on reuse, on how the graph shows in TensorBoard and so on.\n",
    "\n",
    "3. will make the name of all operations added within it have a prefix.\n",
    "    1. `Generator(x)` and `Discriminator(x)` are called ops/operations\n",
    "    \n",
    "4. usually used to group some variables together in an op. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator(x):\n",
    "    hidden_layer = tf.nn.relu(tf.add(tf.matmul(x, weights[\"disc_H\"]), biases[\"disc_H\"]))\n",
    "    final_layer = tf.add(tf.matmul(hidden_layer, weights[\"disc_final\"]), biases[\"disc_final\"])\n",
    "    disc_output = tf.nn.sigmoid(final_layer)\n",
    "    return final_layer, disc_output\n",
    "\n",
    "def Generator(x):\n",
    "    hidden_layer = tf.nn.relu(tf.add(tf.matmul(x, weights[\"gen_H\"]), biases[\"gen_H\"]))\n",
    "    final_layer = tf.add(tf.matmul(hidden_layer, weights[\"gen_final\"]), biases[\"gen_final\"])\n",
    "    gen_output = tf.nn.sigmoid(final_layer)\n",
    "    return gen_output\n",
    "\n",
    "# placeholders for external inputs\n",
    "z_input = tf.placeholder(tf.float32, shape=[None, z_noise_dim], name=\"input_noise\")\n",
    "x_input = tf.placeholder(tf.float32, shape=[None, image_dim], name=\"real_input\")\n",
    "\n",
    "# build the generator network\n",
    "with tf.name_scope(\"Generator\") as scope:\n",
    "    output_gen = Generator(z_input) # implements G(z)\n",
    "    \n",
    "# build the discriminator network\n",
    "with tf.name_scope(\"Discriminator\") as scope:\n",
    "    real_output1_disc, real_output_disc = Discriminator(x_input) # implements D(x)\n",
    "    fake_output1_disc, fake_output_disc = Discriminator(output_gen) # implements D(G(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Discriminator_Loss\") as scope:\n",
    "    # expectation value of log(D(x))+log(1-D(G(x)))\n",
    "    # 0.0001 is added so that the log term doesn't unexpectedly blow up on optimisation\n",
    "    \n",
    "    # negative value if taken here, since the tensorflow by default minimizes the loss, but we want to maximise it\n",
    "    # hence on putting a negative sign, tensorflow will end up doing our desired optimization(primal-dual form)\n",
    "    Discriminator_Loss = -tf.reduce_mean(tf.log(real_output_disc+0.0001)+tf.log(1.-fake_output_disc+0.0001))\n",
    "    \n",
    "    \n",
    "with tf.name_scope(\"Generator_Loss\") as scope:\n",
    "    # expectation value of log(1-D(G(x))) or rather log(D(G(x))), \n",
    "    # since the former function has very small gradient value at the beginning iterations(vanishing gradients)\n",
    "    # 0.0001 is added so that the log term doesn't unexpectedly blow up on optimisation\n",
    "    Generator_Loss = -tf.reduce_mean(tf.log(fake_output_disc+0.0001))\n",
    "    \n",
    "disc_loss_total = tf.summary.scalar(\"Disc_Total_loss\", Discriminator_Loss)\n",
    "gen_loss_total = tf.summary.scalar(\"Gen_loss\", Generator_Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`var_list`: Optional list or tuple of `tf.Variable` to update to minimize loss.\n",
    "\n",
    "`minimize`\n",
    "* Add operations to minimize `loss`(here the value of this argument is `Discriminator_Loss`/`Generator_Loss`) by updating `var_list`.\n",
    "\n",
    "* This method simply combines calls `compute_gradients()` and `apply_gradients()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_var = [weights[\"gen_H\"], weights[\"gen_final\"], biases[\"gen_H\"], biases[\"gen_final\"]]\n",
    "discriminator_var = [weights[\"disc_H\"], weights[\"disc_final\"], biases[\"disc_H\"], biases[\"disc_final\"]]\n",
    "\n",
    "# define the optimizer\n",
    "with tf.name_scope(\"Optimizer_Discriminator\") as scope:\n",
    "    # var_list: update only those variables in this list\n",
    "    # hence generator is kept constant while training the discriminator\n",
    "    Discriminator_optimize = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(Discriminator_Loss, var_list=discriminator_var)\n",
    "    \n",
    "\n",
    "with tf.name_scope(\"Optimizer_Generator\") as scope:\n",
    "    Generator_optimize = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(Generator_Loss, var_list=generator_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.summary.FileWrite`\n",
    "1. The FileWriter class provides a mechanism to create an event file in a given directory and add summaries and events to it. \n",
    "\n",
    "2. The class updates the file contents **asynchronously**. \n",
    "\n",
    "    1. This allows a training program to call methods to add data to the file directly from the training loop, without slowing down training.\n",
    "    \n",
    "3. the method `add_summary()`\n",
    "    \n",
    "    1. Adds a Summary protocol buffer to the event file.\n",
    "    \n",
    "    2. This method wraps the provided summary in an Event protocol buffer and adds it to the event file.\n",
    "    \n",
    "    3. Can pass the result of evaluating any summary op, using `tf.Session.run`(<font color=\"purple\">we have done this</font>) or `tf.Tensor.eval`, to this function. \n",
    "    \n",
    "    1. `global_step`:\tNumber. Optional global step value to record with the summary.\n",
    "\n",
    "* as mentioned earlier and expected here , the `init` represents the method-call to `global_variables_initializer`, and is then called by the `session.run`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "writer = tf.summary.FileWriter(\"./log\", sess.graph)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    x_batch = fetchBatch()\n",
    "    \n",
    "    # generator noise to feed to generator\n",
    "    z_noise = np.random.uniform(-1., 1., size=[batch_size, z_noise_dim])\n",
    "    _, disc_loss_epoch = sess.run([Discriminator_optimize, Discriminator_Loss], feed_dict = {x_input: x_batch, z_input: z_noise})\n",
    "    _, gen_loss_epoch = sess.run([Generator_optimize, Generator_Loss], feed_dict = {z_input: z_noise})\n",
    "    \n",
    "    # run discriminator summary\n",
    "    summary_disc_loss = sess.run(disc_loss_total, feed_dict = {x_input: x_batch, z_input: z_noise})\n",
    "    \n",
    "    # add discriminator summary\n",
    "    writer.add_summary(summary_disc_loss, epoch)\n",
    "    \n",
    "    # run generator summary\n",
    "    summary_gen_loss = sess.run(gen_loss_total, feed_dict = {z_input: z_noise})\n",
    "    \n",
    "    # add generator summary\n",
    "    writer.add_summary(summary_gen_loss, epoch)\n",
    "    \n",
    "    if epoch % 2000 == 0:\n",
    "        print(\"Steps: {0}, generator loss : {1}, discriminator loss : {2}\".format(epoch, gen_loss_epoch, disc_loss_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after training the GAN, actually generate the images from the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 6\n",
    "# canvas = np.empty((28*n, 28*n))\n",
    "\n",
    "# for i in range(n):\n",
    "#     # noise input\n",
    "#     z_noise = np.random.uniform(-1., 1., size=[batch_size, z_noise_dim])\n",
    "#     g = sess.run(output_gen, feed_dict = {z_input: z_noise})\n",
    "    \n",
    "#     # reverse colors for better display\n",
    "#     g = -1 * (g-1)\n",
    "    \n",
    "#     for j in range(n):\n",
    "#         # draw the generated images\n",
    "#         canvas[i*28:(i+1)*28, j*28:(j+1)*28] = g[j].reshape([28, 28])\n",
    "\n",
    "# plt.figure(figsize=(n, n))\n",
    "# plt.imshow(canvas, origin=\"upper\", cmap=\"gray\")\n",
    "# plt.show()\n",
    "\n",
    "z_noise = np.random.uniform(-1., 1., size=[batch_size, z_noise_dim])\n",
    "g = sess.run(output_gen, feed_dict = {z_input: z_noise})\n",
    "print(g.shape) # 128,784\n",
    "\n",
    "# extract first image generated\n",
    "im1 = g[0]\n",
    "im1 = im1.reshape((28, 28))\n",
    "print(im1.shape) # 28, 28\n",
    "\n",
    "plt.imshow(im1, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = resize(im1, (256, 256))\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "plt.imshow(im1, origin=\"upper\", cmap=\"Greys\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
