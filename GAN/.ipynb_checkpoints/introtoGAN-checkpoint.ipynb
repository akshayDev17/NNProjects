{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- generative adversarial network\n",
    "\n",
    "    - generative: generate a new probability distribution function that *in-th-end* mimics the original probability distribution of a dataset\n",
    "    \n",
    "    - adversarial: some conflict or opposition, as exists between the 2 NNs, generator and discriminator, which compete against each other\n",
    "\n",
    "- 2 main neural-net models:\n",
    "\n",
    "    - **discriminator**:\n",
    "    \n",
    "        - discriminates between 2 different classes of data\n",
    "        \n",
    "        - for instance, a model built to detect *fake vs real* usually uses this. in such case the model outputs 1 ==> real, 0 ===> fake\n",
    "        \n",
    "    - **generator**:\n",
    "    \n",
    "        - trained on training data, sampled from some true distribution D, and when given some standard random distribution Z(of some other parameters), produces a distribution $\\hat{\\textrm{D}}$ which is as close to D according to some closeness metric.\n",
    "        \n",
    "        - symbolically represented as G.\n",
    "        \n",
    "        - G(Z) = $\\hat{\\textrm{D}}$, such that $\\hat{\\textrm{D}}$ $\\approx$ D\n",
    "        \n",
    "- hence, G learns to generate a sample, and then discriminator is the one that checks whether this sample is a fake or not, and if discriminator says that its a fake, G has to learn something more(i.e. optimise some objective function), so as to generate a sample which the discriminator actually classifies as a real sample, and in this way $\\hat{\\textrm{D}}$ $\\approx$ D\n",
    "\n",
    "- if decision made by the discriminator is wrong, feedback to fine-tune it, and fine-tuning of the generator, as part of backprop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Mechanism\n",
    "\n",
    "- weights and biases for each of the generator and discriminator\n",
    "- while training one the other is held constant, i.e. not trained\n",
    "- <font size=\"4\">training the discriminator</font> is much easier\n",
    "    - label the artificial instances(samples generated by the generator) as y = 0, real instances(from true dataset) as y=1\n",
    "    - these 2 collection of samples are then combined into 1 large set, and the discriminator learns to output y = 0 or y=1, thus the discriminator is involved with a binary classification task\n",
    "- <font size=\"4\">training the generator</font>\n",
    "    - the discriminator weights and biases are kept fixed, so that it doesn't become so strong such that the generator is never able to beat it\n",
    "    - while training the generator, its outputs, i.e. the artificial instances are labelled 1, so as to fool the discriminator into believing that its been provided with real samples\n",
    "    - if the discriminator is rather strong enough to classify this artificial instance as y=0, we backprop this information to, the weights and biases for the generator are adjusted, upto an extent where the discriminator outputs the label as 0.5, meaning that it has become confused, or in other words, *generator has become smart enough* to fool the discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function of GAN\n",
    "\n",
    "\n",
    "## Notations\n",
    "- p.d.f. of true dataset d$_{\\textrm{true}}$: p$_{\\textrm{data}}$(x), where x = true sample belonging to d$_{\\textrm{true}}$, and X = random variable that denotes the sample belonging to d$_{\\textrm{true}}$\n",
    "\n",
    "- discriminator D(x; $\\theta$) ==> variables before \";\" are input parameters, after \";\" are parameters that we need to optimize\n",
    "    - x is passed into D(x; $\\theta_2$), which gives us D(x), a p.d.f. that denotes probability of x belonging in D, i.e. being a true/real sample\n",
    "    \n",
    "    - since its a p.d.f., D(x) $\\epsilon$\\[0, 1\\]\n",
    "\n",
    "- a priori probability distribution on the input noise variable p$_{\\textrm{Z}}$(z) is defined, which will be fed into the generator G(z; $\\theta_1$)\n",
    "\n",
    "    - the generator outputs a sample, x$_{\\textrm{G}}$\n",
    "    \n",
    "    - goal: p$_{\\textrm{G}}$(x$_{\\textrm{G}}$) = p$_{\\textrm{data}}$(x)\n",
    "    \n",
    "    - this sample is also fed to the D(x; $\\theta_2$), with a label = 0\n",
    "    \n",
    "    - the output, when an artificial sample is given to the discriminator, which is a p.d.f., just like D(x), is D(G(z))\n",
    "\n",
    "- <font color=\"red\">Note</font>: G() and D() are differentiable functions, or else updation will not be possible\n",
    "\n",
    "## Binary crossentropy loss\n",
    "\n",
    "- L(y, $\\hat{\\textrm{y}}$) = ylog($\\hat{\\textrm{y}}$) + (1-y)log(1-$\\hat{\\textrm{y}}$)\n",
    "\n",
    "- for samples coming from d$_{\\textrm{true}}$, y = 1, $\\hat{\\textrm{y}}$ = D(x) \n",
    "    \n",
    "    - hence, L(1, D(x)) = log(D(x))\n",
    "    \n",
    "- for samples coming from generator, y = 0, $\\hat{\\textrm{y}}$ = D(G(z))\n",
    "    \n",
    "    - hence, L(0, D(G(z) ) = log( 1 - D(G(z)) )\n",
    "\n",
    "## Discriminator\n",
    "\n",
    "- objective: correctly classifiy fake from real\n",
    "\n",
    "- maximise L(1, D(x) ) and L(0, D(G(x) ), since these are the loss functions for the discriminator\n",
    "\n",
    "- we already know that D(x) and D(G(z)) are p.d.f.'s, \n",
    "    \n",
    "    - hence log(D(x)) $\\epsilon (-\\infty$, 0], so the max value for this function is 0, which means that D(x) = 1.\n",
    "    \n",
    "    - hence 1-D(G(z)) $\\epsilon [0, 1]$, which means that log( 1 - D(G(z)) ) $\\epsilon \\, (-\\infty$, 0], so the max value for this function is 0, which means that D(G(z)) = 0\n",
    "    \n",
    "- these results are anyways expected, i.e. sample from the generator should be classified as to having 0 probability of belonging in d$_{\\textrm{true}}$, and samples from d$_{\\textrm{true}}$ should be classified as to having full probability of belonging in d$_{\\textrm{true}}$\n",
    "\n",
    "- hence, the net loss function becomes L = max.( log(D(x)) + log( 1 - D( G(z) ) ) )\n",
    "\n",
    "## Generator\n",
    "\n",
    "- so as to fool the discriminator, all the generator has to do is D(G(z)) = 1, since this corresponds to being classified as a true sample\n",
    "\n",
    "- this basically means that log(1 - D(G(z)) ) $\\rightarrow -\\infty$ \n",
    "<img src=\"generator.png\"/>\n",
    "    \n",
    "- hence the goal is to min. ( log(1 - D(G(z)) ) )\n",
    "    \n",
    "    - its actually generally represented as min.( log(D(x)) + log(1 - D(G(z)) ) ), although D(x) has nothing to do with generator G.\n",
    "    \n",
    "\n",
    "Hence its very obvious that the generator and discriminator have the exact **<font color=\"red\">opposite</font>** objective functions, and that's why the term **adversarial** is used\n",
    "\n",
    "min.$_{\\textrm{G}}$ max.$_{\\textrm{D}}$ (log(D(x)) + log(1 - D(G(z)) ))\n",
    "\n",
    "<font size=\"4\">On including all training samples, we get</font>:\\\n",
    "V(G, D) = min.$_{\\textrm{G}}$ max.$_{\\textrm{D}}$ ( <font size=\"4\">E$_{x \\epsilon p_{\\textrm{data}}(x)}$</font>$\\left[\\textrm{log}\\left(D(x)\\right)\\right]$ +  <font size=\"4\">E$_{z \\epsilon p_{\\textrm{z}}(Z)}$</font>$\\left[\\textrm{log}\\left(1-D(G(z))\\right)\\right]$), where E: expectation value over the respective p.d.f. of p$_{\\textrm{data}}$(x) and p$_{\\textrm{z}}$(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best discriminator\n",
    "\n",
    "- fix G, optimal discriminator D is given by:\n",
    "    - D$_{\\textrm{G}}^{*}$(x) =  $\\frac{\\textrm{p}_{\\textrm{data}}(x)}{\\textrm{p}_{\\textrm{data}}(x)+\\textrm{p}_{\\textrm{G}}(x)}$\n",
    "\n",
    "- since G is fixed, the loss function becomes max.(sum-of-expected-values)\n",
    "\n",
    "- E$_{\\textrm{p(x)}}$\\[x\\] = $\\int_{\\textrm{x}}xp(x)dx$\n",
    "    \n",
    "- hence V(G, D) = max.$_{\\textrm{D}}$(<font size=\"4\">E$_{x \\epsilon p_{\\textrm{data}}(x)}$</font>$\\left[\\textrm{log}\\left(D(x)\\right)\\right]$ +  <font size=\"4\">E$_{z \\epsilon p_{\\textrm{z}}(Z)}$</font>$\\left[\\textrm{log}\\left(1-D(G(z))\\right)\\right]$)\n",
    "    \n",
    "    - \\begin{equation}\n",
    "        V(G, D) = \\int_x p_{\\textrm{data}}(x)\\textrm{log(D(x))dx} + \\int_z p_{\\textrm{z}}(z)\\textrm{log(1-D(G(z)))dz} \\end{equation}\n",
    "        \n",
    "- for a given p.d.f. p$_x$(x), the p.d.f. of a function f(x) can also be calculated\n",
    "    \n",
    "    - this is called change of variable\n",
    "    \n",
    "    - P$_y$(y) = p$_x(f^{-1}(y)) \\frac{d(f^{-1}(y)}{dy} $, where y = f(x)\n",
    "    \n",
    "- we know that our generator produces x' = G(z), such that we want the distribution of this x' to mimic that of x\n",
    "    \n",
    "    - thus, we get p$_{\\textrm{G}}$(x') = p$_{\\textrm{z}}(G^{-1}) \\frac{d(G^{-1}(x')}{dx'}$\n",
    "    \n",
    "    - **strong assumption: G is invertible**\n",
    "    \n",
    "    - performing *change of variable* for the expression $\\int_z p_{\\textrm{z}}(z)\\textrm{log(1-D(G(z)))dz}$, we get $\\int_{x'} p_{\\textrm{z}}(G^{-1}(x'))\\textrm{log(1-D(x'))}dG^{-1}(x')$\n",
    "    \n",
    "    - multiplying and dividing the above expression by dx', inside the integral, we obtain $\\int_{x'} p_{\\textrm{z}}(G^{-1}(x'))\\frac{dG^{-1}(x')}{dx'} $ . log(1-D(x'))dx'\n",
    "    \n",
    "    - this becomes $\\int_{x'} \\textrm{p}_{\\textrm{G}}(x') $ . log(1-D(x'))dx' \n",
    "    \n",
    "\n",
    "- hence V(G, D) = $\\int_x p_{\\textrm{data}}(x)\\textrm{log(D(x))dx}$  + $\\int_{x'} \\textrm{p}_{\\textrm{G}}(x')$. log(1-D(x'))dx'\n",
    "\n",
    "    - we assume that our generator is currently doing its best, i.e. its generating x' with the same distribution as x, thus making x' = x\n",
    "    \n",
    "    - hence V(G, D) = $\\int_x \\left(p_{\\textrm{data}}(x)\\textrm{log(D(x))} \\, + \\, \\textrm{p}_{\\textrm{G}}(x).log(1-D(x))\\right)dx$\n",
    "    \n",
    "- this above V(G, D) needs to be maximised, which means that the first derivative w.r.t. D(x) should be 0, since the **argument here is D(x)**, i.e. the discriminator, and not the random variable x.\n",
    "    \n",
    "    - $\\frac{d(V(G, D))}{dD(x)}_{D = D^{*}} = 0$\n",
    "    \n",
    "    - $\\frac{d(V(G, D))}{dD(x)}$ = $\\frac{p_{\\textrm{data}}(x)}{\\textrm{D(x)}} \\, - \\, \\frac{\\textrm{p}_{\\textrm{G}}(x)}{1-D(x)}$ = 0 \n",
    "    \n",
    "    - on rearranging the terms, we finally obtain: <font size=\"4\"> D$_{\\textrm{G}}^{*}$(x) =  $\\frac{\\textrm{p}_{\\textrm{data}}(x)}{\\textrm{p}_{\\textrm{data}}(x)+\\textrm{p}_{\\textrm{G}}(x)}$</font>\n",
    "    \n",
    "    - just to prove that D is maximum at this value, lets evaluate $\\frac{d^2(V(G, D))}{dD(x)^2}$:\n",
    "    \\begin{equation}\n",
    "    \\frac{d^2(V(G, D))}{dD(x)^2} = -\\frac{p_{\\textrm{data}}(x)}{\\textrm{D(x)}^{2}} - \\frac{\\textrm{p}_{\\textrm{G}}(x)}{\\left(1-D(x)\\right)^{2}} \\\\\n",
    "    \\textrm{since   } p_{\\textrm{data}}(x) \\, \\epsilon \\, [0, 1] \\textrm{ and } p_{\\textrm{G}}(x) \\, \\epsilon \\, [0, 1] \\, \\, \\Rightarrow \\, \\, D_{\\textrm{G}}^{*}\\textrm{(x)} \\ge 0\n",
    "    \\end{equation}\n",
    "    \n",
    "    - hence the second derivative is negative, thus proving that this is in fact the value at which the objective is maximized.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the best generator\n",
    "\n",
    "- now that the best discriminator is known, lets keep it fixed and try to optimise for the generator, i.e. min.$_{\\textrm{G}}$(V(G, D$_{\\textrm{G}}^{*}$(x)))\n",
    "\n",
    "- optimal generator should have the condition that p$_{\\textrm{G}}$(x) = p$_{\\textrm{data}}$(x)\n",
    "\n",
    "- using D$_{\\textrm{G}}^{*}$(x) =  $\\frac{\\textrm{p}_{\\textrm{data}}(x)}{\\textrm{p}_{\\textrm{data}}(x)+\\textrm{p}_{\\textrm{G}}(x)}$, we get: V(G, D$_{\\textrm{G}}^{*}$(x)) = $\\int_x \\left(p_{\\textrm{data}}(x)\\textrm{log}\\left(\\frac{\\textrm{p}_{\\textrm{data}}(x)}{\\textrm{p}_{\\textrm{data}}(x)+\\textrm{p}_{\\textrm{G}}(x)}\\right) \\, + \\, \\textrm{p}_{\\textrm{G}}(x).log\\left(\\frac{\\textrm{p}_{\\textrm{G}}(x)}{\\textrm{p}_{\\textrm{data}}(x)+\\textrm{p}_{\\textrm{G}}(x)}\\right)\\right)dx$\n",
    "\n",
    "- now add and subtract these 2 terms : log(2).p$_{\\textrm{data}}$(x) , log(2).p$_{\\textrm{G}}$(x)\\\n",
    "we thus have $\\int_x \\left(-\\log2.\\left(p_{\\textrm{data}}(x)+ p_{\\textrm{G}}(x)\\right)\\, + \\, p_{\\textrm{data}}(x)\\textrm{log}\\left(\\frac{2.\\textrm{p}_{\\textrm{data}}(x)}{\\textrm{p}_{\\textrm{data}}(x)+\\textrm{p}_{\\textrm{G}}(x)}\\right) \\, + \\, \\textrm{p}_{\\textrm{G}}(x).log\\left(\\frac{2.\\textrm{p}_{\\textrm{G}}(x)}{\\textrm{p}_{\\textrm{data}}(x)+\\textrm{p}_{\\textrm{G}}(x)}\\right)\\right)dx$\n",
    "\n",
    "    - this simplifies to <font size=\"4\" color=\"red\">-log4 + KL$\\left[p_{\\textrm{data}}(x) || \\frac{\\textrm{p}_{\\textrm{data}}(x) + \\textrm{p}_{\\textrm{G}}(x)}{2}\\right]$ + KL$\\left[p_{\\textrm{G}}(x) || \\frac{\\textrm{p}_{\\textrm{data}}(x) + \\textrm{p}_{\\textrm{G}}(x)}{2}\\right]$ </font>\n",
    "\n",
    "- remember that x' = G(z), z = random noise, x' = sample generated by the generator\n",
    "    \n",
    "    - also <font color=\"red\" size=\"4\">p$_{\\textrm{G}}$(x') = p$_{\\textrm{z}}(G^{-1}) \\frac{d(G^{-1}(x')}{dx'}$</font>\n",
    "    \n",
    "- the summation of KL-divergence above is represented by a new divergence function, called the **Jensen-Shanon Divergence** \n",
    "    \n",
    "    - JSD(a || b) = $\\frac{1}{2}\\left[ \\textrm{KL(a||c)} +  \\textrm{KL(b||c)} \\right]$, where c = $\\frac{\\textrm{a+b}}{2}$\n",
    "    \n",
    "- KL divergence becomes 0 at p$_{\\textrm{G}}$(x) = p$_{\\textrm{data}}$(x) (2 same quantities)\n",
    "\n",
    "- **hence, tuning the JSD to 0 is the main objective**\n",
    "\n",
    "- observe that when G = G*, p$_{\\textrm{G}}$(x) = p$_{\\textrm{data}}$(x), even if D = D$_{\\textrm{G}}^{*}$,<font size=\"4\" color=\"red\">D = 1/2</font>, hence our generator has confused even the best discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the loss function\n",
    "\n",
    "- <font size=\"5\" color=\"blue\">for the j$^{\\textrm{th}}$ iteration</font>:\n",
    "    - <font size=\"4\" color=\"purple\">for k steps do</font>:\n",
    "        * Sample mini-batch of **m noise samples** {z$^{(1)}$, z$^{(2)}$, .... z$^{(\\textrm{m})}$ } from noise prior p$_{\\textrm{G}}$(z)\n",
    "        * Sample mini-batch of **m data samples** {x$^{(1)}$, x$^{(2)}$, .... x$^{(\\textrm{m})}$ } from dataset-distribution, p$_{\\textrm{data}}$(x)\n",
    "        * Update the discriminator by **ascending**(<font color=\"green\">since we want to maximise the cost w.r.t. discriminator</font>) its *stochastic*(basically for the current mini-batch) gradient)\\\n",
    "            $\\nabla$<font size=\"4\">$_{\\theta_{\\textrm{d}}}$</font> $\\frac{1}{\\textrm{m}} \\sum \\limits_{\\textrm{i=1}}^{\\textrm{m}} $log(D(x$^{(\\textrm{i})}$)) + log( 1 - D( G(z$^{(\\textrm{i})}$) ) ), where $\\theta_{\\textrm{d}}$ denoted parameters of the discriminator network\n",
    "    * <font size=\"4\" color=\"purple\">endfor</font>\n",
    "    * Sample mini-batch of **m noise samples** {z$^{(1)}$, z$^{(2)}$, .... z$^{(\\textrm{m})}$ } from noise prior p$_{\\textrm{G}}$(z)\n",
    "    * Update the generator by **descending**(<font color=\"red\">since we want to minimise the cost w.r.t. generator</font>) its *stochastic*(basically for the current mini-batch) gradient)\n",
    "        * $\\nabla$<font size=\"4\">$_{\\theta_{\\textrm{g}}}$</font> $\\frac{1}{\\textrm{m}} \\sum \\limits_{\\textrm{i=1}}^{\\textrm{m}}$ log( 1 - D( G(z$^{(\\textrm{i})}$) ) ), where $\\theta_{\\textrm{g}}$ denoted parameters of the generator network\n",
    "* <font size=\"5\" color=\"blue\">endfor</font>\n",
    "* practically speaking, at the starting iterations of this loss function, when the generator isn't itself *smart enough* to fool the discriminator, i.e. discriminator can easily identify the sample produced by the generator, D(G(z)) = 0\n",
    "    \n",
    "    * hence the gradient for the loss function log(1 - D(G(z)) is almost 0, since tangent drawn to y = log(1-D(G(z))) at D(G(z)) = 0  is almost a flat one, it would seem as if convergence criterion has reached, but its not so\n",
    "    * to overcome this, in practical scenarios, the function <font size=\"4\">argmax$_{\\textrm{G}}$(E$_{p_{z}(z)}$[log(D(G(z))])</font> is used instead\n",
    "    \n",
    "    * even for the initial iterations where D(G(z)) = 0, the slope would be very large, thus informing the model that we have a lot to go before concluding that convergence is achieved. Also, since the gradient is high, it usually corresponds to a jump in the steepest descent algorithm for optimisation.\n",
    "    \n",
    "    * don't worry, <font size=\"4\" color=\"blue\">the objective for the discriminator remains the same</font>, since it doesn't suffer from this gradient-problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawbacks of GAN\n",
    "\n",
    "1. Vanishing Gradients\n",
    "    \n",
    "    1. this is observed for the generator, and that's why the objective was changed, as mentioned in the previous section.\n",
    "    \n",
    "    2. let $\\theta_{\\textrm{g}} = \\theta,\\,\\, \\theta_{\\textrm{d}} = \\phi$, $\\frac{\\partial \\textrm{V(G, D)}}{\\partial \\theta} = \\nabla_{\\theta}$[E$_{p_{z}(z)}$[log(1-D$_{\\phi}$(G$_{\\theta}$(z)))]] = E<font size=\"4\">$_{\\textrm{p}_{\\textrm{z}}(z)}\\left[ \\frac{\\partial \\textrm{G}_{\\theta}(z)}{\\partial \\theta} \\frac{1}{\\textrm{D}_{\\phi}(\\textrm{G}_{\\theta}(z))-1} \\frac{\\partial \\textrm{D}_{\\phi}(\\textrm{G}_{\\theta}(z))}{\\partial \\textrm{G}_{\\theta}(z)} \\right]$</font>\n",
    "    \n",
    "    3. we already know that for perfect generator, x' = x, i.e. x = G(z), E<font size=\"4\">$_{\\textrm{p}_{\\textrm{G}}(x)}$ = $ \\frac{\\partial x}{\\partial \\theta} \\frac{1}{\\textrm{D(x)-1}} \\frac{\\partial D(x)}{\\partial x}$</font>\n",
    "    \n",
    "    4. with our basic assumption that after **k steps, a perfect discriminator is obtained**, which will be able to perfectly classify D(G(x)), or rather samples generated from generator, as always being D(X) = 0. Hence all samples drawn from the generator will have D(x) = 0, hence the derivative of D(x) w.r.t. $\\theta$ turns to 0.\n",
    "    \n",
    "    5. this is the mathematical display of vanishing gradients for the generator\n",
    "    \n",
    "    6. changing the loss function to max.(log(D$_{\\phi}$(G$_{\\theta}$(x)))) or to put it more precisely, max.(E$_{\\textrm{p}_{\\textrm{z}}(z)}$\\[log(D$_{\\phi}$(G$_{\\theta}$(x)))\\])\n",
    "    \n",
    "2. Mode Collapse\n",
    "    \n",
    "    1. generator collapses to a setting where it ends up **always producing the same outputs**\n",
    "    \n",
    "    2. the p.d.f. function of the true dataset is a complex, multi-modal function, having different peaks such that there can be a subset of all classes concentrated in these peaks\n",
    "    \n",
    "    3. lets consider MNIST hadnwritten-digit dataset\n",
    "    \n",
    "    4. it may so happen that we have different curves for p.d.f. for each class(not talking about the p.d.f. of the true entire data here). \\\n",
    "    We can see below that 0 can be represented in first gaussian, and 9 can be represented in the last one \n",
    "    \n",
    "    5. hence the generator might find it hard to learn this multi-modal distribution(here modes means total number of classes) and since its main objective is to fool the discriminator, <font color=\"green\">instead of learning from all modes</font>, <font color=\"red\">it may just end up learning from 1 of these modes in a near-perfect manner</font>(this is an easier task), such that its easily able to replicate the samples that constitute that particular mode.\n",
    "    \n",
    "    6. as the discriminator gets better w.r.t. telling apart the artificial and real samples belonging to 1 mode, the generator has to either produce better samples for that mode or it can simply learn to produce better samples from some other mode for which the discriminator has not yet learnt to tell the real-n-fake apart.\n",
    "    \n",
    "    7. hence, in the above point, if the generator ends up picking the former option many number of times, mode collapse will occur, or at-the-very-least has high chances of occurring.\n",
    "    \n",
    "    8. an analogy to understand this is that *instead of becoming a jack of all trades*, <u>the generator decides to become the master of one</u>\n",
    "    \n",
    "3. hard to achieve Nash equilibrium\n",
    "\n",
    "    1. [Salimans 2016](https://arxiv.org/abs/1606.03498) discusses this problem in detail\n",
    "    \n",
    "    2. principally GANs should train in such a way that both the generator and dsicriminator find a nash equilibrium at the end of this *2 player, non-cooperative game.*\n",
    "    \n",
    "    3. however, each model updates its cost with no regards of how the other is updating itself.\n",
    "    \n",
    "    4. hence the gradients of both models, **<font color=\"red\">concurrently cannot guarantee convergence</font>**\n",
    "    \n",
    "    5. lets assume f$_1$(x) = xy, f$_2$(y) = -xy, such that their respective objectives are to maximize and minimize x.y\n",
    "    \n",
    "    6. with each update of these functions, huge oscillations in these functions, instability becomes worse with time\n",
    "    \n",
    "4. Problem with counting\n",
    "    \n",
    "    1. fail to differentiate between number of objects that should occur in a generated image\n",
    "    \n",
    "5. Problem with perspective\n",
    "    \n",
    "    1. unable to differentiate between the front view and rear view\n",
    "    \n",
    "    2. this is seen when GANs are learning from 3D-objects(images are 3D in a sense that some perspective is involved in that image) to generate their 2D images.\n",
    "    \n",
    "6. problem with gloabl structure\n",
    "\n",
    "    1. problems in understanding holistic structure similar to the above perspective problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_cpu] *",
   "language": "python",
   "name": "conda-env-tensorflow_cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
