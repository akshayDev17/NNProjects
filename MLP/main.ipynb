{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3904ed7b-b5eb-4515-bf70-18bae4d00c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshayprabhakant/miniconda3/lib/python3.9/site-packages/scipy/__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.21.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.datasets as skds\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e3f48b8-ec3c-4474-8744-ae87ff475fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(x):\n",
    "    return 1 if x>=0 else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a7633b7-a4e7-44e9-a00e-b23fa909352e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(sign(-1));print(sign(0));print(sign(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fbabb02-6691-4bde-ba6e-53d180f8dd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, in_dim, out_dim, learning_rate = 0.1, weights=None, tol=0.0001):\n",
    "        self.in_dim=in_dim\n",
    "        self.out_dim=out_dim\n",
    "        self.activation = np.vectorize(sign)\n",
    "        self.learning_rate=learning_rate\n",
    "        self.tol = tol\n",
    "        if weights is None:\n",
    "            # initialize weights as in_dim X out_dim matrix\n",
    "            self.weights=np.ones((in_dim+1,out_dim))\n",
    "        else:\n",
    "            self.weights=weights\n",
    "            # sanity check\n",
    "            weights_in, weights_out = self.weights.shape\n",
    "            if (weights_in != in_dim and weights_in != in_dim+1) or weights_out != out_dim:\n",
    "                raise Exception(\"Supplied weight matrix has shape mismatch with either in_dim (and in_dim+1) or out_dim.\")\n",
    "\n",
    "            # check whether bias term exists in given weight matrix\n",
    "            if self.weights.shape[0] != in_dim+1:\n",
    "                bias_arr = np.ones((1, out_dim))\n",
    "                self.weights = np.vstack((self.weights, bias_arr))\n",
    "\n",
    "    def gradient(self, X, y):\n",
    "        gradient_mat = np.zeros(self.weights.shape)\n",
    "        for i in range(X.shape[0]):\n",
    "            x_i, y_i = X[i, :], y[i]\n",
    "            f_x_i = self.activation(x_i.dot(self.weights)[0])\n",
    "            if y_i*f_x_i < 0:\n",
    "                gradient_mat += -x_i[:, np.newaxis]*y_i\n",
    "        return gradient_mat\n",
    "\n",
    "    def weight_update(self, X, y):\n",
    "        self.weights -= self.learning_rate * self.gradient(X, y)\n",
    "\n",
    "    def fit(self, X, y, iter=1000):\n",
    "        # sanity check\n",
    "        if self.in_dim != X.shape[1]:\n",
    "            raise Exception(\"Supplied input matrix X has shape mismatch with either in_dim or in_dim+1 of layer being fit over.\")\n",
    "        if len(y.shape) < 2:\n",
    "            # 1D np array\n",
    "            if self.out_dim != 1:\n",
    "                raise Exception(\"Supplied target matrix y has shape mismatch with either out_dim of layer being fit over.\")\n",
    "        else:\n",
    "            if self.out_dim != y.shape[1]:\n",
    "                raise Exception(\"Supplied target matrix y has shape mismatch with either out_dim of layer being fit over.\")\n",
    "\n",
    "        x_new = X.copy()\n",
    "        bias_arr = np.ones((x_new.shape[0], 1))\n",
    "        x_new = np.hstack((x_new, bias_arr)) # appended bias column vector\n",
    "\n",
    "        # change 1,0 -> 1,-1\n",
    "        val_1, val_2 = np.unique(y)\n",
    "        self.target_encoder = {\n",
    "            val_1: 1,\n",
    "            val_2: -1\n",
    "        }\n",
    "\n",
    "        self.target_decoder = {\n",
    "            1: val_1,\n",
    "            -1: val_2\n",
    "        }\n",
    "\n",
    "        # Define a mapping function using lambda and the dictionary\n",
    "        mapping_function = lambda x: self.target_encoder.get(x, x)\n",
    "        \n",
    "        # Use numpy.vectorize to apply the mapping function element-wise\n",
    "        mapped_y = np.vectorize(mapping_function)(y)\n",
    "        \n",
    "        prev_quarter_num = 0\n",
    "        lr_orig_val = self.learning_rate\n",
    "        loss_arr = []\n",
    "        for iter_num in range(iter):\n",
    "            loss_arr.append(self.loss(X, y))\n",
    "            quarter_num = int(math.floor((iter_num*4)/iter))\n",
    "            if quarter_num != prev_quarter_num:\n",
    "                # block change, reduce learning rate\n",
    "                self.learning_rate *= 0.9\n",
    "                print(self.learning_rate)\n",
    "                prev_quarter_num = quarter_num\n",
    "            self.weight_update(x_new, mapped_y)\n",
    "        self.loss_arr = loss_arr\n",
    "        self.learning_rate = lr_orig_val\n",
    "\n",
    "    def loss(self, X, y):\n",
    "        y_pred = self.predict(X) # this will have original data's split.\n",
    "        \n",
    "        # convert y_pred and y to -1,1 representation\n",
    "        mapped_y = np.vectorize(lambda x: self.target_encoder.get(x, x))(y)\n",
    "        mapped_y_pred = np.vectorize(lambda x: self.target_encoder.get(x, x))(y_pred)\n",
    "        \n",
    "        y_i_f = -mapped_y_pred*mapped_y[:, np.newaxis]\n",
    "        loss_vec_evaluated = np.vectorize(lambda x: max(0, x))(y_i_f)\n",
    "        return np.sum(loss_vec_evaluated)\n",
    "      \n",
    "    def predict(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        x_new = X.copy()\n",
    "        if n_features < self.weights.shape[0]:\n",
    "            # add column of ones to X\n",
    "            x_new = np.hstack((x_new, np.ones((X.shape[0], 1))))\n",
    "        \n",
    "        # Define a reverse mapping function using lambda and the dictionary\n",
    "        reverse_mapping_function = lambda x: self.target_decoder.get(x, x)\n",
    "        return np.vectorize(reverse_mapping_function)(self.activation(x_new.dot(self.weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97229571-1389-429c-92e3-60959376cf34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "data = skds.load_breast_cancer(as_frame=True)\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64e379a8-ba29-4357-9421-f335e477cfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "5        12.45         15.70           82.57      477.1          0.12780   \n",
       "6        18.25         19.98          119.60     1040.0          0.09463   \n",
       "7        13.71         20.83           90.20      577.9          0.11890   \n",
       "8        13.00         21.82           87.50      519.8          0.12730   \n",
       "9        12.46         24.04           83.97      475.9          0.11860   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760         0.30010              0.14710         0.2419   \n",
       "1           0.07864         0.08690              0.07017         0.1812   \n",
       "2           0.15990         0.19740              0.12790         0.2069   \n",
       "3           0.28390         0.24140              0.10520         0.2597   \n",
       "4           0.13280         0.19800              0.10430         0.1809   \n",
       "5           0.17000         0.15780              0.08089         0.2087   \n",
       "6           0.10900         0.11270              0.07400         0.1794   \n",
       "7           0.16450         0.09366              0.05985         0.2196   \n",
       "8           0.19320         0.18590              0.09353         0.2350   \n",
       "9           0.23960         0.22730              0.08543         0.2030   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "5                 0.07613  ...          23.75           103.40       741.6   \n",
       "6                 0.05742  ...          27.66           153.20      1606.0   \n",
       "7                 0.07451  ...          28.14           110.60       897.0   \n",
       "8                 0.07389  ...          30.73           106.20       739.3   \n",
       "9                 0.08243  ...          40.68            97.65       711.4   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "5            0.1791             0.5249           0.5355                0.1741   \n",
       "6            0.1442             0.2576           0.3784                0.1932   \n",
       "7            0.1654             0.3682           0.2678                0.1556   \n",
       "8            0.1703             0.5401           0.5390                0.2060   \n",
       "9            0.1853             1.0580           1.1050                0.2210   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "5          0.3985                  0.12440       0  \n",
       "6          0.3063                  0.08368       0  \n",
       "7          0.3196                  0.11510       0  \n",
       "8          0.4378                  0.10720       0  \n",
       "9          0.4366                  0.20750       0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aaaed9c-2df5-462c-b909-d7f230ca5d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "564    0\n",
      "565    0\n",
      "566    0\n",
      "567    0\n",
      "568    1\n",
      "Name: target, Length: 569, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X, y = data.data, data.target\n",
    "display(X.head(5));print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc706acb-828e-4033-a9a8-e3bc66030cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    357\n",
      "0    212\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50ca3e9c-85ee-4feb-a767-a45e5cb90b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30) (143, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=442)\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758cc651-3684-47ca-965f-6167dd647085",
   "metadata": {},
   "source": [
    "## Our Implementation\n",
    "Lets see how our implementation fares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfa060ff-b972-460e-b7d4-e746cff3651a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009000000000000001\n",
      "0.008100000000000001\n",
      "0.007290000000000001\n"
     ]
    }
   ],
   "source": [
    "custom_p = Perceptron(in_dim=x_train.shape[1], out_dim=1, learning_rate = 0.01)\n",
    "custom_p.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dca4f27c-05db-4f51-b5dc-4c3fc800625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = custom_p.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20d8dd27-c5a5-4af1-902b-44ad4d9e06e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([ 43, 100]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_pred, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44c6c746-cada-4b4a-b3e4-07add1cf66cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(custom_p.loss(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "432c5162-0c27-40f3-9acf-3b8d38fe5b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(custom_p.loss_arr)), custom_p.loss_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd586ff7-845f-46be-8784-d3237cdc3f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.923,\n",
      "Precision: 0.92,\n",
      "Recall: 0.968,\n",
      "F1: 0.944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(f\"Accuracy: {round(accuracy_score(y_test, y_pred), 3)},\\nPrecision: {round(precision_score(y_test, y_pred), 3)},\\nRecall: {round(recall_score(y_test, y_pred), 3)},\\nF1: {round(f1_score(y_test, y_pred), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1842a322-4c26-4e5d-bbcf-1712a93e915c",
   "metadata": {},
   "source": [
    "## scikit-learn's Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01a3e90e-f9ef-43a3-b457-b065585c39f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "p = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "369f1290-48f3-4647-b8a5-c101febbbff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddd8acf3-c1d4-4fb6-80d5-18bf65c4bb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8741258741258742\n"
     ]
    }
   ],
   "source": [
    "print(p.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83613238-174e-46a3-af3e-a1313cfeed36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision=0.841, Recall=1.0, F1=0.913\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred = p.predict(x_test)\n",
    "print(f\"Precision={round(precision_score(y_test, y_pred), 3)}, Recall={round(recall_score(y_test, y_pred), 3)}, F1={round(f1_score(y_test, y_pred), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1246e637-ce17-4f29-8d11-86d8b71ff58b",
   "metadata": {},
   "source": [
    "Lets look at the loss function and other parameters of this perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57a27ace-e2a6-4a2f-956c-bd3811231f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sklearn.linear_model._sgd_fast.Hinge object at 0x163cbd470>\n"
     ]
    }
   ],
   "source": [
    "print(p.loss_function_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a9abd28-7f97-46b5-829a-420cc9a12fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001, 'class_weight': None, 'early_stopping': False, 'eta0': 1.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': None, 'random_state': 0, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(p.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c8d9e6-d9d4-45bd-9ce4-ab49cf812e98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
